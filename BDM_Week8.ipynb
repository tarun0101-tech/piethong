{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjA+313HATN0aDV91D451i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarun0101-tech/piethong/blob/master/BDM_Week8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMfS0kVPAfvw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "413b36d7-97ce-4e1c-abee-e8c59ce20b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8706e304a98f>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  week1_shifts['Availability'] = week1_shifts['Shift 1 (8 Hours)'].apply(lambda x: 1 if x == 'Operational' else 0)\n",
            "<ipython-input-3-8706e304a98f>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  week1_shifts['Availability'] = week1_shifts['Shift 2 (8 Hours)'].apply(lambda x: 1 if x == 'Operational' else 0)\n",
            "<ipython-input-3-8706e304a98f>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  week1_shifts['Availability'] = week1_shifts['Shift 3 (8 Hours)'].apply(lambda x: 1 if x == 'Operational' else 0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Shift'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8706e304a98f>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Calculate Performance and Quality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mweek1_shifts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweek1_shifts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweek1_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Shift'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mweek1_shifts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweek1_shifts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweek1_scrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Shift'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10485\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10487\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10489\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    167\u001b[0m         )\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Shift'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the Excel file\n",
        "file_path = '/content/sample_data/BDM_week8/dataset_8_276.xlsx'\n",
        "shift_running_df = pd.read_excel(file_path, sheet_name='Shift_Running')\n",
        "actual_output_df = pd.read_excel(file_path, sheet_name='Actual_Output')\n",
        "scrap_df = pd.read_excel(file_path, sheet_name='Scrap')\n",
        "\n",
        "# Define the date range for Week-1\n",
        "week1_start = '2022-04-01'\n",
        "week1_end = '2022-04-07'\n",
        "\n",
        "# Filter data for Week-1\n",
        "week1_shifts = shift_running_df[(shift_running_df['Date'] >= week1_start) & (shift_running_df['Date'] <= week1_end)]\n",
        "week1_output = actual_output_df[(actual_output_df['Date'] >= week1_start) & (actual_output_df['Date'] <= week1_end)]\n",
        "week1_scrap = scrap_df[(scrap_df['Date'] >= week1_start) & (scrap_df['Date'] <= week1_end)]\n",
        "\n",
        "# Define the Rated Output\n",
        "rated_output = 4000\n",
        "\n",
        "# Calculate Availability\n",
        "# Availability is 1 for operational shifts and 0 for non-operational shifts\n",
        "week1_shifts['Availability'] = week1_shifts['Shift 1 (8 Hours)'].apply(lambda x: 1 if x == 'Operational' else 0)\n",
        "week1_shifts['Availability'] = week1_shifts['Shift 2 (8 Hours)'].apply(lambda x: 1 if x == 'Operational' else 0)\n",
        "week1_shifts['Availability'] = week1_shifts['Shift 3 (8 Hours)'].apply(lambda x: 1 if x == 'Operational' else 0)\n",
        "\n",
        "# Calculate Performance and Quality\n",
        "week1_shifts = week1_shifts.merge(week1_output, on=['Date', 'Shift'], how='left')\n",
        "week1_shifts = week1_shifts.merge(week1_scrap, on=['Date', 'Shift'], how='left')\n",
        "\n",
        "# Replace NaN values with 0 for Actual Output and Scrap\n",
        "week1_shifts['Actual_Output'] = week1_shifts['Actual_Output'].fillna(0)\n",
        "week1_shifts['Scrap'] = week1_shifts['Scrap'].fillna(0)\n",
        "\n",
        "# Performance Calculation\n",
        "week1_shifts['Performance'] = week1_shifts['Actual_Output'] / rated_output\n",
        "\n",
        "# Quality Calculation\n",
        "week1_shifts['Accepted_Parts'] = week1_shifts['Actual_Output'] - week1_shifts['Scrap']\n",
        "week1_shifts['Quality'] = week1_shifts['Accepted_Parts'] / week1_shifts['Actual_Output']\n",
        "\n",
        "# Handle divisions by zero for Quality (when Actual Output is 0)\n",
        "week1_shifts['Quality'] = week1_shifts['Quality'].replace([pd.np.inf, -pd.np.inf, pd.np.nan], 0)\n",
        "\n",
        "# Calculate OEE\n",
        "week1_shifts['OEE'] = week1_shifts['Availability'] * week1_shifts['Performance'] * week1_shifts['Quality']\n",
        "\n",
        "# Calculate average OEE for Week-1\n",
        "average_oee_week1 = week1_shifts['OEE'].mean()\n",
        "\n",
        "average_oee_week1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the Excel file\n",
        "file_path = '/content/sample_data/BDM_week8/dataset_8_276.xlsx'\n",
        "shift_running_df = pd.read_excel(file_path, sheet_name='Shift_Running')\n",
        "actual_output_df = pd.read_excel(file_path, sheet_name='Actual_Output')\n",
        "scrap_df = pd.read_excel(file_path, sheet_name='Scrap')\n",
        "\n",
        "# Define the Rated Output\n",
        "rated_output = 4000\n",
        "\n",
        "# Prepare a list to store OEE calculations\n",
        "oee_results = []\n",
        "\n",
        "# Loop through each row (date) in Shift_Running\n",
        "for index, row in shift_running_df.iterrows():\n",
        "    date = row['Date']\n",
        "\n",
        "    # Loop through each shift\n",
        "    for shift in ['Shift 1 (8 Hours)', 'Shift 2 (8 Hours)', 'Shift 3 (8 Hours)']:\n",
        "        shift_status = row[shift]\n",
        "\n",
        "        # Determine Availability\n",
        "        availability = 1 if shift_status == 'Operational' else 0\n",
        "\n",
        "        # Get the corresponding Actual Output and Scrap values\n",
        "        actual_output = actual_output_df.loc[(actual_output_df['Date'] == date) & (actual_output_df['Shift'] == shift), 'Actual_Output'].values[0]\n",
        "        scrap = scrap_df.loc[(scrap_df['Date'] == date) & (scrap_df['Shift'] == shift), 'Scrap'].values[0]\n",
        "\n",
        "        # Calculate Performance\n",
        "        performance = actual_output / rated_output if rated_output != 0 else 0\n",
        "\n",
        "        # Calculate Quality\n",
        "        quality = (actual_output - scrap) / actual_output if actual_output != 0 else 0\n",
        "\n",
        "        # Calculate OEE\n",
        "        oee = availability * performance * quality\n",
        "\n",
        "        # Store the OEE calculation\n",
        "        oee_results.append({\n",
        "            'Date': date,\n",
        "            'Shift': shift,\n",
        "            'Availability': availability,\n",
        "            'Performance': performance,\n",
        "            'Quality': quality,\n",
        "            'OEE': oee\n",
        "        })\n",
        "\n",
        "# Convert the results to a DataFrame\n",
        "oee_df = pd.DataFrame(oee_results)\n",
        "\n",
        "# Calculate the average OEE for all shifts and dates\n",
        "average_oee = oee_df['OEE'].mean()\n",
        "\n",
        "# Display the average OEE\n",
        "average_oee\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "ZDoVMhYEo17L",
        "outputId": "5fe11eff-53ac-4618-ddba-b2f5630999f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Shift'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Shift'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b595946b8b68>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Get the corresponding Actual Output and Scrap values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mactual_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactual_output_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_output_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactual_output_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Shift'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Actual_Output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mscrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrap_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrap_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscrap_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Shift'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Scrap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m             ):\n\u001b[1;32m   3797\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Shift'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the Excel file\n",
        "file_path = '/content/sample_data/BDM_week8/dataset_8_276.xlsx'\n",
        "shift_running_df = pd.read_excel(file_path, sheet_name='Shift_Running')\n",
        "actual_output_df = pd.read_excel(file_path, sheet_name='Actual_Output')\n",
        "scrap_df = pd.read_excel(file_path, sheet_name='Scrap')\n",
        "\n",
        "# Define the Rated Output\n",
        "rated_output = 4000\n",
        "\n",
        "# Prepare a list to store OEE calculations\n",
        "oee_results = []\n",
        "\n",
        "# Loop through each row (date) in Shift_Running\n",
        "for index, row in shift_running_df.iterrows():\n",
        "    date = row['Date']\n",
        "\n",
        "    # Loop through each shift\n",
        "    for shift in ['Shift 1', 'Shift 2', 'Shift 3']:\n",
        "        shift_status = row[shift]\n",
        "\n",
        "        # Determine Availability\n",
        "        availability = 1 if shift_status == 'Operational' else 0\n",
        "\n",
        "        # Get the corresponding Actual Output and Scrap values\n",
        "        actual_output = actual_output_df.loc[actual_output_df['Date'] == date, shift].values[0]\n",
        "        scrap = scrap_df.loc[scrap_df['Date'] == date, shift].values[0]\n",
        "\n",
        "        # Calculate Performance\n",
        "        performance = actual_output / rated_output if rated_output != 0 else 0\n",
        "\n",
        "        # Calculate Quality\n",
        "        quality = (actual_output - scrap) / actual_output if actual_output != 0 else 0\n",
        "\n",
        "        # Calculate OEE\n",
        "        oee = availability * performance * quality\n",
        "\n",
        "        # Store the OEE calculation\n",
        "        oee_results.append({\n",
        "            'Date': date,\n",
        "            'Shift': shift,\n",
        "            'Availability': availability,\n",
        "            'Performance': performance,\n",
        "            'Quality': quality,\n",
        "            'OEE': oee\n",
        "        })\n",
        "\n",
        "# Convert the results to a DataFrame\n",
        "oee_df = pd.DataFrame(oee_results)\n",
        "\n",
        "# Calculate the average OEE for all shifts and dates\n",
        "average_oee = oee_df['OEE'].mean()\n",
        "\n",
        "# Display the average OEE\n",
        "average_oee\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXTNUsA0qaw8",
        "outputId": "d633e254-6a36-4780-b3d7-2dad29b5cf07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8971428571428571"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/sample_data/BDM_week8/dataset_8_276.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load each sheet into a DataFrame\n",
        "shift_running_df = pd.read_excel(xls, 'Shift_Running')\n",
        "actual_output_df = pd.read_excel(xls, 'Actual_Output')\n",
        "scrap_df = pd.read_excel(xls, 'Scrap')\n",
        "\n",
        "# Display the first few rows of each dataframe to understand their structure\n",
        "shift_running_df.head(), actual_output_df.head(), scrap_df.head()\n",
        "\n",
        "# Filtering data for Week 1 (01-04-2022 to 07-04-2022)\n",
        "week_1_dates = pd.date_range(start=\"2022-04-01\", end=\"2022-04-07\")\n",
        "shift_running_week_1 = shift_running_df[shift_running_df['Date'].isin(week_1_dates)]\n",
        "actual_output_week_1 = actual_output_df[actual_output_df['Date'].isin(week_1_dates)]\n",
        "scrap_week_1 = scrap_df[scrap_df['Date'].isin(week_1_dates)]\n",
        "\n",
        "# Calculate Availability for each shift\n",
        "availability = shift_running_week_1.replace({\n",
        "    'Operational': 1,\n",
        "    'Planned Maintenance': 0,\n",
        "    'Power Cut': 0,\n",
        "    'Breakdown': 0,\n",
        "    'Unplanned Maintenance': 0\n",
        "}).iloc[:, 1:].sum().sum() / (7 * 3) # 7 days, 3 shifts per day\n",
        "\n",
        "# Calculate Performance for each shift\n",
        "total_output = actual_output_week_1.iloc[:, 1:].sum().sum()\n",
        "total_scrap = scrap_week_1.iloc[:, 1:].sum().sum()\n",
        "performance = total_output / (total_output + total_scrap) if (total_output + total_scrap) != 0 else 0\n",
        "\n",
        "# Calculate Quality for each shift\n",
        "quality = (total_output - total_scrap) / total_output if total_output != 0 else 0\n",
        "\n",
        "# Calculate OEE for Week 1\n",
        "oee_week_1 = availability * performance * quality\n",
        "print(oee_week_1)\n",
        "\n",
        "# Calculate total output and total scrap for the entire fortnight (all 14 days)\n",
        "total_output_fortnight = actual_output_df.iloc[:, 1:].sum().sum()\n",
        "total_scrap_fortnight = scrap_df.iloc[:, 1:].sum().sum()\n",
        "\n",
        "# Calculate the overall quality of the Part-A manufacturing process\n",
        "overall_quality_fortnight = (total_output_fortnight - total_scrap_fortnight) / total_output_fortnight if total_output_fortnight != 0 else 0\n",
        "\n",
        "print(overall_quality_fortnight)\n",
        "\n",
        "# Filtering data for Week 2 (08-04-2022 to 14-04-2022)\n",
        "week_2_dates = pd.date_range(start=\"2022-04-08\", end=\"2022-04-14\")\n",
        "actual_output_week_2 = actual_output_df[actual_output_df['Date'].isin(week_2_dates)]\n",
        "scrap_week_2 = scrap_df[scrap_df['Date'].isin(week_2_dates)]\n",
        "\n",
        "# Calculate total output and total scrap for Week 2\n",
        "total_output_week_2 = actual_output_week_2.iloc[:, 1:].sum().sum()\n",
        "total_scrap_week_2 = scrap_week_2.iloc[:, 1:].sum().sum()\n",
        "\n",
        "# Calculate the performance for Week 2\n",
        "performance_week_2 = total_output_week_2 / (total_output_week_2 + total_scrap_week_2) if (total_output_week_2 + total_scrap_week_2) != 0 else 0\n",
        "print(performance_week_2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj0cgF07we3g",
        "outputId": "78a76189-cd68-4be4-dc77-6b9875949199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8959097063971729\n",
            "0.997432309337417\n",
            "0.9946457529497288\n"
          ]
        }
      ]
    }
  ]
}